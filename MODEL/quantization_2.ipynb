{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkBVk68ZiFJaLvPvFJv1vy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnVPhYsKTxgH","executionInfo":{"status":"ok","timestamp":1744785425434,"user_tz":-330,"elapsed":54785,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"ef925282-7a7a-4153-b95c-7ec43bbcc0d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!pip install onnx onnxruntime onnxruntime-tools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVY5L7HRVeNB","executionInfo":{"status":"ok","timestamp":1744785776614,"user_tz":-330,"elapsed":8470,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"c9e49108-8bb5-4f7b-86c1-8d999d28c186"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting onnxruntime-tools\n","  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (9.0.0)\n","Collecting py3nvml (from onnxruntime-tools)\n","  Downloading py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Collecting xmltodict (from py3nvml->onnxruntime-tools)\n","  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n","Installing collected packages: xmltodict, onnx, py3nvml, onnxruntime, onnxruntime-tools\n","Successfully installed onnx-1.17.0 onnxruntime-1.21.0 onnxruntime-tools-1.7.0 py3nvml-0.2.7 xmltodict-0.14.2\n"]}]},{"cell_type":"code","source":["!pip install ultralytics\n","!pip install onnxruntime-gpu"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"pfoYOLk1UpZ_","executionInfo":{"status":"ok","timestamp":1744785653193,"user_tz":-330,"elapsed":97297,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"46cd997f-827a-4b06-9bc2-183cb9840260"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.109 ultralytics-thop-2.0.14\n","Collecting onnxruntime-gpu\n","  Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n","Collecting coloredlogs (from onnxruntime-gpu)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (5.29.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.13.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n","Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.21.0\n"]}]},{"cell_type":"code","source":["# Step 1: Export YOLOv8 model to ONNX format\n","from ultralytics import YOLO\n","import os\n","import onnx\n","import numpy as np\n","from onnxruntime.quantization import quantize_static, QuantType\n","\n","# Load your model\n","model_path = \"/content/drive/MyDrive/saved_model/best.pt\"\n","model = YOLO(model_path)\n","\n","# Export to ONNX format\n","onnx_path = model.export(format=\"onnx\", simplify=True)\n","print(f\"Model exported to ONNX: {onnx_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tj1bVDtGT55P","executionInfo":{"status":"ok","timestamp":1744785937251,"user_tz":-330,"elapsed":15597,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"c4ffca05-7002-4c66-85e5-6c70e515a467"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.109 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (AMD EPYC 7B12)\n","YOLOv8n-cls summary (fused): 30 layers, 1,454,095 parameters, 0 gradients, 3.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/saved_model/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 15) (2.9 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim'] not found, attempting AutoUpdate...\n","Collecting onnxslim\n","  Downloading onnxslim-0.1.50-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.17.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.13.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim) (24.2)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxslim) (2.0.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxslim) (5.29.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim) (1.3.0)\n","Downloading onnxslim-0.1.50-py3-none-any.whl (144 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.5/144.5 kB 4.9 MB/s eta 0:00:00\n","Installing collected packages: onnxslim\n","Successfully installed onnxslim-0.1.50\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 4.1s, installed 1 package: ['onnxslim']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 6.4s, saved as '/content/drive/MyDrive/saved_model/best.onnx' (5.6 MB)\n","\n","Export complete (8.0s)\n","Results saved to \u001b[1m/content/drive/MyDrive/saved_model\u001b[0m\n","Predict:         yolo predict task=classify model=/content/drive/MyDrive/saved_model/best.onnx imgsz=224  \n","Validate:        yolo val task=classify model=/content/drive/MyDrive/saved_model/best.onnx imgsz=224 data=yolo_classification_dataset  \n","Visualize:       https://netron.app\n","Model exported to ONNX: /content/drive/MyDrive/saved_model/best.onnx\n"]}]},{"cell_type":"code","source":["\n","# Step 2: Prepare calibration data (required for static quantization)\n","# This is a simplified example - ideally use actual data from your dataset\n","def representative_data_gen():\n","    # Generate 20 sample images (random data in this example)\n","    for _ in range(20):\n","        # Create random input in the expected shape [1, 3, 640, 640]\n","        # Adjust the shape based on your model's input requirements\n","        input_shape = model.model.yaml.get('imgsz', 640)\n","        if isinstance(input_shape, int):\n","            input_shape = [input_shape, input_shape]\n","        sample = np.random.random((1, 3, input_shape[0], input_shape[1])).astype(np.float32)\n","        yield [sample]"],"metadata":{"id":"W1aYMU4dUVtN","executionInfo":{"status":"ok","timestamp":1744785977924,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","# Step 3: Create a calibration dataset file for quantization\n","calibration_data_file = \"calibration.npz\"\n","calibration_data = []\n","\n","print(\"Generating calibration data...\")\n","for data in representative_data_gen():\n","    calibration_data.append(data[0])\n","\n","np.savez(calibration_data_file, *calibration_data)\n","print(f\"Calibration data saved to {calibration_data_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTAE6s4DUYTs","executionInfo":{"status":"ok","timestamp":1744786036157,"user_tz":-330,"elapsed":357,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"a1284df5-41f7-442f-b135-7a3daedbd812"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating calibration data...\n","Calibration data saved to calibration.npz\n"]}]},{"cell_type":"code","source":["# Step 4: Perform static quantization to INT8\n","print(\"Starting INT8 quantization...\")\n","quantized_model_path = onnx_path.replace('.onnx', '_quantized_int8.onnx')\n","\n","# Configure quantization options\n","quantize_static(\n","    model_input=onnx_path,\n","    model_output=quantized_model_path,\n","    calibration_data_path=calibration_file,\n","    quant_format=QuantType.QInt8,\n","    per_channel=False,\n","    weight_type=QuantType.QInt8,\n",")\n","\n","print(f\"INT8 quantized model saved to {quantized_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"vxvjQyKeUalU","executionInfo":{"status":"error","timestamp":1744786205559,"user_tz":-330,"elapsed":40,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"8229f3e6-993c-4f31-9460-49ec6952d20f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting INT8 quantization...\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'calibration_file' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-41ca4016f666>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantized_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcalibration_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalibration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mquant_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQuantType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQInt8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mper_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'calibration_file' is not defined"]}]},{"cell_type":"code","source":["\n","\n","\n","# Step 5: Compare model sizes\n","original_size = os.path.getsize(onnx_path) / (1024 * 1024)\n","quantized_size = os.path.getsize(quantized_model_path) / (1024 * 1024)\n","\n","print(f\"Original ONNX model size: {original_size:.2f} MB\")\n","print(f\"Quantized INT8 model size: {quantized_size:.2f} MB\")\n","print(f\"Reduction: {(1 - quantized_size/original_size) * 100:.1f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"c7hdCyBXUjrU","executionInfo":{"status":"error","timestamp":1744786201081,"user_tz":-330,"elapsed":100,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"4dcc5539-ad61-4c7f-830a-9e3602687a8b"},"execution_count":14,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/saved_model/best_quantized_int8.onnx'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-f64d813c786f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 5: Compare model sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moriginal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mquantized_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantized_model_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original ONNX model size: {original_size:.2f} MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/saved_model/best_quantized_int8.onnx'"]}]},{"cell_type":"code","source":["\n","\n","\n","# Optional: If you want to try TFLite as well\n","# Step 6: Export to TFLite format with INT8 quantization\n","tf_path = model.export(format=\"tflite\", int8=True)\n","print(f\"Model exported to TFLite with INT8 quantization: {tf_path}\")\n","\n","tflite_size = os.path.getsize(tf_path) / (1024 * 1024)\n","print(f\"TFLite INT8 model size: {tflite_size:.2f} MB\")\n","print(f\"Reduction from original: {(1 - tflite_size/original_size) * 100:.1f}%\")"],"metadata":{"id":"hvgdi9iVUmSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simplified approach focusing on TFLite export which has more stable API\n","from ultralytics import YOLO\n","import os\n","\n","# Step 1: Load your model\n","model_path = \"/content/drive/MyDrive/saved_model/best.pt\"\n","model = YOLO(model_path)\n","\n","print(\"Model loaded successfully!\")\n","\n","# First approach: Try TFLite with INT8 quantization\n","# This is often the easiest and most reliable approach\n","try:\n","    print(\"\\nExporting to TFLite with INT8 quantization...\")\n","    tf_path = model.export(format=\"tflite\", int8=True)\n","    print(f\"✅ Success! Model exported to: {tf_path}\")\n","\n","    original_size = os.path.getsize(model_path) / (1024 * 1024)\n","    tflite_size = os.path.getsize(tf_path) / (1024 * 1024)\n","    print(f\"Original model size: {original_size:.2f} MB\")\n","    print(f\"TFLite INT8 model size: {tflite_size:.2f} MB\")\n","    print(f\"Reduction: {(1 - tflite_size/original_size) * 100:.1f}%\")\n","except Exception as e:\n","    print(f\"❌ TFLite export failed: {e}\")\n","    print(\"You may need to install tensorflow: pip install tensorflow\")\n","\n","# Second approach: Alternative ONNX approach with simpler quantization\n","try:\n","    print(\"\\nExporting to ONNX format...\")\n","    onnx_path = model.export(format=\"onnx\", simplify=True)\n","    print(f\"✅ Success! ONNX model exported to: {onnx_path}\")\n","\n","    # Manual ONNX INT8 conversion using the correct current API\n","    import onnx\n","    from onnxruntime.quantization import quantize_dynamic, QuantType\n","\n","    print(\"\\nApplying dynamic quantization to ONNX model...\")\n","    quantized_model_path = onnx_path.replace('.onnx', '_quantized_int8.onnx')\n","\n","    # Dynamic quantization is more reliable and doesn't need calibration data\n","    quantize_dynamic(\n","        model_input=onnx_path,\n","        model_output=quantized_model_path,\n","        weight_type=QuantType.QInt8\n","    )\n","\n","    print(f\"✅ Success! Quantized model saved to: {quantized_model_path}\")\n","\n","    onnx_size = os.path.getsize(onnx_path) / (1024 * 1024)\n","    quantized_size = os.path.getsize(quantized_model_path) / (1024 * 1024)\n","    print(f\"ONNX model size: {onnx_size:.2f} MB\")\n","    print(f\"Quantized ONNX model size: {quantized_size:.2f} MB\")\n","    print(f\"Reduction: {(1 - quantized_size/onnx_size) * 100:.1f}%\")\n","except Exception as e:\n","    print(f\"❌ ONNX quantization failed: {e}\")\n","    print(\"Try installing: pip install onnx onnxruntime\")\n","\n","# For debugging\n","import sys\n","print(f\"\\nPython version: {sys.version}\")\n","try:\n","    import onnxruntime\n","    print(f\"ONNXRuntime version: {onnxruntime.__version__}\")\n","except:\n","    print(\"ONNXRuntime not installed\")\n","\n","try:\n","    import tensorflow\n","    print(f\"TensorFlow version: {tensorflow.__version__}\")\n","except:\n","    print(\"TensorFlow not installed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QkIyw_WhXP6f","executionInfo":{"status":"ok","timestamp":1744786351593,"user_tz":-330,"elapsed":61374,"user":{"displayName":"Harsha Srinivas","userId":"16954004141711859577"}},"outputId":"8bccf576-d5d5-46e1-8f88-826f89ea0781"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n","\n","Exporting to TFLite with INT8 quantization...\n","Ultralytics 8.3.109 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (AMD EPYC 7B12)\n","WARNING ⚠️ INT8 export requires a missing 'data' arg for calibration. Using default 'data=imagenet10'.\n","YOLOv8n-cls summary (fused): 30 layers, 1,454,095 parameters, 0 gradients, 3.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/saved_model/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 15) (2.9 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3', 'tflite_support'] not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Collecting sng4onnx>=1.0.1\n","  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n","Collecting onnx_graphsurgeon>=0.3.26\n","  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n","Collecting ai-edge-litert>=1.2.0\n","  Downloading ai_edge_litert-1.2.0-cp311-cp311-manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting onnx2tf>=1.26.3\n","  Downloading onnx2tf-1.27.2-py3-none-any.whl.metadata (147 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.7/147.7 kB 5.2 MB/s eta 0:00:00\n","Collecting tflite_support\n","  Downloading tflite_support-0.4.4-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon>=0.3.26) (2.0.2)\n","Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon>=0.3.26) (1.17.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.2.0) (25.2.10)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tflite_support) (1.4.0)\n","Collecting protobuf<4,>=3.18.0 (from tflite_support)\n","  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Collecting sounddevice>=0.4.4 (from tflite_support)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Collecting pybind11>=2.6.0 (from tflite_support)\n","  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.22)\n","Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n","Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.9/57.9 kB 213.2 MB/s eta 0:00:00\n","Downloading ai_edge_litert-1.2.0-cp311-cp311-manylinux_2_17_x86_64.whl (3.5 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 54.3 MB/s eta 0:00:00\n","Downloading onnx2tf-1.27.2-py3-none-any.whl (446 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.6/446.6 kB 30.3 MB/s eta 0:00:00\n","Downloading tflite_support-0.4.4-cp311-cp311-manylinux2014_x86_64.whl (60.8 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 MB 95.6 MB/s eta 0:00:00\n","Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.1/162.1 kB 250.3 MB/s eta 0:00:00\n","Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 243.3/243.3 kB 317.5 MB/s eta 0:00:00\n","Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sng4onnx, pybind11, protobuf, onnx2tf, ai-edge-litert, sounddevice, tflite_support, onnx_graphsurgeon\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.4\n","    Uninstalling protobuf-5.29.4:\n","      Successfully uninstalled protobuf-5.29.4\n","Successfully installed ai-edge-litert-1.2.0 onnx2tf-1.27.2 onnx_graphsurgeon-0.5.8 protobuf-3.20.3 pybind11-2.13.6 sng4onnx-1.0.4 sounddevice-0.5.1 tflite_support-0.4.4\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 29.4s, installed 5 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3', 'tflite_support']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.11M/1.11M [00:00<00:00, 5.24MB/s]\n","Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 58.88file/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.4s, saved as '/content/drive/MyDrive/saved_model/best.onnx' (5.6 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=imagenet10'\n","\n","Dataset not found ⚠️, missing path /content/datasets/imagenet10, attempting download...\n","Downloading https://ultralytics.com/assets/imagenet10.zip to '/content/datasets/imagenet10.zip'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 71.1k/71.1k [00:00<00:00, 803kB/s]\n","Unzipping /content/datasets/imagenet10.zip to /content/datasets/imagenet10...: 100%|██████████| 24/24 [00:00<00:00, 4303.69file/s]"]},{"output_type":"stream","name":"stdout","text":["Dataset download success ✅ (1.5s), saved to \u001b[1m/content/datasets/imagenet10\u001b[0m\n","\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagenet10/train... found 12 images in 10 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagenet10/val... found 12 images in 10 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m None...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Scanning /content/datasets/imagenet10/val/n01440764... 0 images, 12 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<00:00, 247.43it/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ No labels found in /content/datasets/imagenet10/val/n01440764.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n","New cache created: /content/datasets/imagenet10/val/n01440764.cache\n","WARNING ⚠️ No labels found in /content/datasets/imagenet10/val/n01440764.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING ⚠️ >300 images recommended for INT8 calibration, found 12 images.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.27.2...\n","Saved artifact at '/content/drive/MyDrive/saved_model/best_saved_model'. The following endpoints are available:\n","\n","* Endpoint 'serving_default'\n","  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 224, 224, 3), dtype=tf.float32, name='images')\n","Output Type:\n","  TensorSpec(shape=(1, 15), dtype=tf.float32, name=None)\n","Captures:\n","  140094394866128: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  140094394865744: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n","  140094394866512: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n","  140094394869776: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  140094394867664: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n","  140094394870736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094394870928: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n","  140094394870160: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094394871312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094394871504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094394873616: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n","  140094394874000: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n","  140094394872656: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n","  140094394874384: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n","  140094394871696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094394871120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094394874192: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n","  140094394872272: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094394872848: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  140094394874960: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n","  140094394874768: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094394874576: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n","  140094394875536: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094264181392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264181776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094394875344: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  140094394875152: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094264181200: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  140094264182928: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094264181968: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  140094264183120: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094264182544: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  140094264183312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  140094394875728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264180816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264183888: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n","  140094264183696: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094264184080: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  140094264182736: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n","  140094264183504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  140094264184272: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n","  140094264184656: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  140094264185040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264184848: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264185616: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  140094264186960: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094264186192: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  140094264187344: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094264186384: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  140094264187536: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094264185808: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  140094264187728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  140094264185232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264184464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264188304: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n","  140094264188112: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  140094264188496: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  140094264187152: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n","  140094264187920: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  140094264188688: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n","  140094264189072: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  140094264189456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264189264: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264190032: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  140094264191376: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  140094264190608: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  140094264191760: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  140094264189648: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264188880: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  140094264191952: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n","  140094264190800: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  140094264190224: TensorSpec(shape=(1, 1, 256, 1280), dtype=tf.float32, name=None)\n","  140094264192144: TensorSpec(shape=(1280,), dtype=tf.float32, name=None)\n","  140094264195408: TensorSpec(shape=(1280, 15), dtype=tf.float32, name=None)\n","  140094264195792: TensorSpec(shape=(), dtype=tf.float32, name=None)\n","  140094264195984: TensorSpec(shape=(15,), dtype=tf.float32, name=None)\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 60.5s, saved as '/content/drive/MyDrive/saved_model/best_saved_model' (18.3 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as '/content/drive/MyDrive/saved_model/best_saved_model/best_int8.tflite' (1.4 MB)\n","\n","Export complete (60.7s)\n","Results saved to \u001b[1m/content/drive/MyDrive/saved_model\u001b[0m\n","Predict:         yolo predict task=classify model=/content/drive/MyDrive/saved_model/best_saved_model/best_int8.tflite imgsz=224 int8 \n","Validate:        yolo val task=classify model=/content/drive/MyDrive/saved_model/best_saved_model/best_int8.tflite imgsz=224 data=yolo_classification_dataset int8 \n","Visualize:       https://netron.app\n","✅ Success! Model exported to: /content/drive/MyDrive/saved_model/best_saved_model/best_int8.tflite\n","Original model size: 2.86 MB\n","TFLite INT8 model size: 1.42 MB\n","Reduction: 50.3%\n","\n","Exporting to ONNX format...\n","Ultralytics 8.3.109 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (AMD EPYC 7B12)\n","YOLOv8n-cls summary (fused): 30 layers, 1,454,095 parameters, 0 gradients, 3.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/saved_model/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 15) (2.9 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.4s, saved as '/content/drive/MyDrive/saved_model/best.onnx' (5.6 MB)\n","\n","Export complete (0.5s)\n","Results saved to \u001b[1m/content/drive/MyDrive/saved_model\u001b[0m\n","Predict:         yolo predict task=classify model=/content/drive/MyDrive/saved_model/best.onnx imgsz=224  \n","Validate:        yolo val task=classify model=/content/drive/MyDrive/saved_model/best.onnx imgsz=224 data=yolo_classification_dataset  \n","Visualize:       https://netron.app\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"]},{"output_type":"stream","name":"stdout","text":["✅ Success! ONNX model exported to: /content/drive/MyDrive/saved_model/best.onnx\n","\n","Applying dynamic quantization to ONNX model...\n","✅ Success! Quantized model saved to: /content/drive/MyDrive/saved_model/best_quantized_int8.onnx\n","ONNX model size: 5.57 MB\n","Quantized ONNX model size: 1.45 MB\n","Reduction: 73.9%\n","\n","Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n","ONNXRuntime version: 1.21.0\n","TensorFlow version: 2.18.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SsK4SwL6XQyt"},"execution_count":null,"outputs":[]}]}