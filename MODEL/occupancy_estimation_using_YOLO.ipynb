{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless tensorflow scikit-learn joblib tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87lCMVHQJOLt",
        "outputId": "3cde1278-ce21-433c-b9e3-c19c6d131fd4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYZ-kCr6KC_D",
        "outputId": "22df29cd-fe19-48c7-c328-053bcaf1c5b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "data_path = '/content/drive/MyDrive/DataCollection'\n",
        "print(\"Classes:\", os.listdir(data_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2EeVo9vKIGy",
        "outputId": "fef82856-dd90-4660-c237-aff18d303ced"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['data_1_person', 'data_2_person', 'data_3_person', 'data_4_person', 'data_6_person', 'data_7_person', 'data_5_person', 'data_8_person', 'data_9_person', 'data_10_person', 'data_11_person', 'data_12_person', 'data_13_person', 'data_14_person', 'data_15_person']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "\n",
        "def horizontal_flip_images(root_path):\n",
        "    for class_folder in os.listdir(root_path):\n",
        "        class_path = os.path.join(root_path, class_folder)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                try:\n",
        "                    image = Image.open(img_path)\n",
        "\n",
        "\n",
        "                    if image.mode == 'RGBA':\n",
        "                        image = image.convert('RGB')\n",
        "\n",
        "                    flipped = ImageOps.mirror(image)\n",
        "                    flipped_name = img_name.rsplit('.', 1)[0] + '_flipped.jpg'\n",
        "                    flipped.save(os.path.join(class_path, flipped_name), 'JPEG')\n",
        "                except Exception as e:\n",
        "                    print(f\"Skipping {img_name}: {e}\")\n",
        "\n",
        "print(\"Flipping images...\")\n",
        "horizontal_flip_images(data_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bMkxRXSKio3",
        "outputId": "88b47464-c93d-47cc-f129-5726df121903"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flipping images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_images_with_labels(path, img_size=(128, 128)):\n",
        "    images, labels = [], []\n",
        "    class_names = sorted(os.listdir(path))\n",
        "    class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        folder = os.path.join(path, class_name)\n",
        "        for img_file in os.listdir(folder):\n",
        "            try:\n",
        "                img = load_img(os.path.join(folder, img_file), target_size=img_size)\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "                images.append(img_array)\n",
        "                labels.append(class_to_idx[class_name])\n",
        "            except Exception as e:\n",
        "                print(\"Skipped:\", img_file, \"Error:\", e)\n",
        "\n",
        "    return np.array(images), np.array(labels), class_to_idx\n",
        "\n",
        "X, y, label_map = load_images_with_labels(data_path)\n",
        "print(\"Loaded:\", len(X), \"images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upCeHvXvKvqa",
        "outputId": "01792ebb-88cf-4657-ffd4-9e23ab544c9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 4052 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X, y = shuffle(X, y, random_state=42)\n"
      ],
      "metadata": {
        "id": "flr64DNUMCwy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "sPNLXRknMJGi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_and_save_dataset(input_dir, output_dir, train_ratio=0.8):\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    test_dir = os.path.join(output_dir, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in os.listdir(input_dir):\n",
        "        class_path = os.path.join(input_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if not images:\n",
        "            print(f\"âš ï¸ No images found in: {class_name}\")\n",
        "            continue\n",
        "\n",
        "        random.shuffle(images)\n",
        "        split_idx = int(len(images) * train_ratio)\n",
        "        train_images = images[:split_idx]\n",
        "        test_images = images[split_idx:]\n",
        "\n",
        "        # Create class folders in train and test\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        test_class_dir = os.path.join(test_dir, class_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "        # Copy train images\n",
        "        for img in train_images:\n",
        "            shutil.copy2(os.path.join(class_path, img), os.path.join(train_class_dir, img))\n",
        "\n",
        "        # Copy test images\n",
        "        for img in test_images:\n",
        "            shutil.copy2(os.path.join(class_path, img), os.path.join(test_class_dir, img))\n",
        "\n",
        "        print(f\"âœ… {class_name}: {len(train_images)} train, {len(test_images)} test images saved.\")\n",
        "\n",
        "    print(\"\\nğŸ“ Dataset split and saved at:\", output_dir)\n",
        "\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/DataCollection'  #  original dataset\n",
        "output_dir = 'yolo_classification_dataset_new'  # Destination for train/test split\n",
        "split_and_save_dataset(input_dir, output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlDZIRfAeC0D",
        "outputId": "50fe69dc-02fb-4a6b-bb4c-c061932f638e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… data_1_person: 153 train, 39 test images saved.\n",
            "âœ… data_2_person: 128 train, 32 test images saved.\n",
            "âœ… data_3_person: 166 train, 42 test images saved.\n",
            "âœ… data_4_person: 108 train, 28 test images saved.\n",
            "âœ… data_6_person: 73 train, 19 test images saved.\n",
            "âœ… data_7_person: 115 train, 29 test images saved.\n",
            "âœ… data_5_person: 81 train, 21 test images saved.\n",
            "âœ… data_8_person: 99 train, 25 test images saved.\n",
            "âœ… data_9_person: 121 train, 31 test images saved.\n",
            "âœ… data_10_person: 83 train, 21 test images saved.\n",
            "âœ… data_11_person: 115 train, 29 test images saved.\n",
            "âœ… data_12_person: 97 train, 25 test images saved.\n",
            "âœ… data_13_person: 78 train, 20 test images saved.\n",
            "âœ… data_14_person: 96 train, 24 test images saved.\n",
            "âœ… data_15_person: 102 train, 26 test images saved.\n",
            "\n",
            "ğŸ“ Dataset split and saved at: yolo_classification_dataset_new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pA0-tYe5Ot3e",
        "outputId": "8bddf410-9806-43b1-96c7-a4168d8f9d94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.104-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.104-py3-none-any.whl (994 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m994.1/994.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.104 ultralytics-thop-2.0.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "8a4d77aca4664eeca37f945713893e55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH_eLaTUO2zn",
        "outputId": "c69dd341-9c17-429b-b98c-12dcd809da75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')\n",
        "\n",
        "model.train(data='yolo_classification_dataset', epochs=15, imgsz=224)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmUE500JPd7a",
        "outputId": "66b4d36f-ebc3-445a-b5b9-b2494452ec62"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.104 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=yolo_classification_dataset, epochs=15, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/yolo_classification_dataset/train... found 3236 images in 15 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/yolo_classification_dataset/test... found 816 images in 15 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=15\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    349455  ultralytics.nn.modules.head.Classify         [256, 15]                     \n",
            "YOLOv8n-cls summary: 56 layers, 1,457,503 parameters, 1,457,503 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_classification_dataset/train... 3236 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3236/3236 [00:02<00:00, 1584.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_classification_dataset/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_classification_dataset/test... 816 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 816/816 [00:00<00:00, 1105.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_classification_dataset/test.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      0.27G      2.809         16        224:   4%|â–         | 8/203 [00:01<00:21,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      0.27G        2.8         16        224:   6%|â–‹         | 13/203 [00:02<00:28,  6.68it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 22.9MB/s]\n",
            "       1/15     0.273G      2.362          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:29<00:00,  6.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.591      0.936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15     0.281G      1.182          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:28<00:00,  7.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.803          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15     0.289G     0.5733          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:27<00:00,  7.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.958          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15     0.299G     0.3481          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:05<00:00,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.973          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15     0.307G     0.2541          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:25<00:00,  7.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:04<00:00,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.975          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15     0.314G     0.1992          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:27<00:00,  7.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.99          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15     0.322G     0.1556          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15     0.332G     0.1445          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:28<00:00,  7.07it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15      0.34G     0.1143          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.52it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15     0.348G     0.1125          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:27<00:00,  7.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:04<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15     0.355G    0.09594          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:25<00:00,  7.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:04<00:00,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.993          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15     0.363G    0.09712          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.996          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15     0.373G    0.09703          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.996          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15     0.381G     0.0831          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.993          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15     0.389G    0.08083          4        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:26<00:00,  7.59it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:03<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.995          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "15 epochs completed in 0.132 hours.\n",
            "Optimizer stripped from runs/classify/train2/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train2/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train2/weights/best.pt...\n",
            "Ultralytics 8.3.104 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,454,095 parameters, 0 gradients, 3.3 GFLOPs\n",
            "WARNING âš ï¸ Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/yolo_classification_dataset/train... found 3236 images in 15 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/yolo_classification_dataset/test... found 816 images in 15 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/yolo_classification_dataset/test... found 816 images in 15 classes âœ… \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:05<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.996          1\n",
            "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7aa5598c8190>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 0.9981617629528046\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.9963235259056091, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9981617629528046}\n",
              "save_dir: PosixPath('runs/classify/train2')\n",
              "speed: {'preprocess': 0.0978823406861537, 'inference': 0.44445013357927543, 'loss': 0.00038997548970468526, 'postprocess': 0.0005446776968626057}\n",
              "task: 'classify'\n",
              "top1: 0.9963235259056091\n",
              "top5: 1.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = 'runs/classify'\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.pt'):\n",
        "            print(\"âœ… Found model:\", os.path.join(root, file))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QichPk6zR5Y",
        "outputId": "4b2cafc8-eded-4a5b-fb4e-76f8d034ed6e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found model: runs/classify/train2/weights/best.pt\n",
            "âœ… Found model: runs/classify/train2/weights/last.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model = YOLO('runs/classify/train2//weights/best.pt')\n",
        "\n",
        "\n",
        "metrics = model.val(data='yolo_classification_dataset')\n",
        "\n",
        "\n",
        "print(f\"\\nâœ… Top-1 Accuracy: {metrics.top1:.4f}\")\n",
        "print(f\"âœ… Top-5 Accuracy: {metrics.top5:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUWUf9nIyXLC",
        "outputId": "a11a3212-b7d1-4ccc-ab0e-fd09813cfcb1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.104 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,454,095 parameters, 0 gradients, 3.3 GFLOPs\n",
            "WARNING âš ï¸ Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/yolo_classification_dataset/train... found 3236 images in 15 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/yolo_classification_dataset/test... found 816 images in 15 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/yolo_classification_dataset/test... found 816 images in 15 classes âœ… \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_classification_dataset/test... 816 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 816/816 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:06<00:00,  8.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.996          1\n",
            "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val3\u001b[0m\n",
            "\n",
            "âœ… Top-1 Accuracy: 0.9963\n",
            "âœ… Top-5 Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil\n",
        "\n",
        "\n",
        "source_path = 'runs/classify/train2/weights/best.pt'\n",
        "destination_path = '/content/drive/MyDrive/saved_model'\n",
        "\n",
        "\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "\n",
        "shutil.copy2(source_path, destination_path)\n",
        "\n",
        "print(f\"âœ… Model saved to: {destination_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OqPX00I4Yv9",
        "outputId": "7afe56c3-aad3-4162-ae25-59289ceacdd7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: /content/drive/MyDrive/saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_path = '/content/drive/MyDrive/yolo_classification_dataset/test/1/9.png'   #single file is uploaded\n",
        "print(\"Image uploaded:\", image_path)\n",
        "\n",
        "\n",
        "try:\n",
        "  from PIL import Image\n",
        "  img = Image.open(image_path)\n",
        "  img.show()\n",
        "  display(img) # Display image inline\n",
        "except Exception as e:\n",
        "  print(f\"Error displaying image: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "rykebi7n0eaU",
        "outputId": "c6406da2-2b99-4fe7-d1d0-dffc963e3239"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image uploaded: /content/drive/MyDrive/yolo_classification_dataset/test/1/9.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=613x460>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# Load your trained model\n",
        "model = YOLO('runs/classify/train2/weights/best.pt')  # update path if needed\n",
        " # replace with your actual image path\n",
        "\n",
        "# Predict\n",
        "image_path = '/content/drive/MyDrive/yolo_classification_dataset/test/1/9.png'\n",
        "results = model(image_path, imgsz=224)\n",
        "\n",
        "# Extract predicted class\n",
        "pred_class_idx = results[0].probs.data.argmax().item()\n",
        "predicted_class = results[0].names[pred_class_idx]\n",
        "\n",
        "print(f\"\\nâœ… Predicted Class: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHefpyK-1QJg",
        "outputId": "e1d9d816-31da-47f8-b4bb-348824113cba"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/yolo_classification_dataset/test/1/9.png: 224x224 data_1_person 1.00, data_4_person 0.00, data_2_person 0.00, data_9_person 0.00, data_11_person 0.00, 3.0ms\n",
            "Speed: 6.2ms preprocess, 3.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "âœ… Predicted Class: data_1_person\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/MyDrive/yolo_classification_dataset/test/10/10- (3).png'\n",
        "img = Image.open(image_path)\n",
        "img.show()\n",
        "display(img)\n",
        "\n",
        "results = model(image_path, imgsz=224)\n",
        "\n",
        "# Extract predicted class\n",
        "pred_class_idx = results[0].probs.data.argmax().item()\n",
        "predicted_class = results[0].names[pred_class_idx]\n",
        "\n",
        "print(f\"\\nâœ… Predicted Class: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "GoPHlefI2R8n",
        "outputId": "af8b7d77-6139-4eb5-ca3f-9b9f89a38575"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/yolo_classification_dataset/test/10/10- (3).png: 224x224 data_10_person 1.00, data_12_person 0.00, data_8_person 0.00, data_2_person 0.00, data_3_person 0.00, 8.0ms\n",
            "Speed: 16.7ms preprocess, 8.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "âœ… Predicted Class: data_10_person\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}